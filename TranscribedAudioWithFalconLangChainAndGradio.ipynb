{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92LXej26WNu8"
      },
      "outputs": [],
      "source": [
        "!pip install assemblyai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ffmpeg-python"
      ],
      "metadata": {
        "id": "Nw86SRlUWXGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers einops accelerate langchain bitsandbytes gradio"
      ],
      "metadata": {
        "id": "ppEwTBjO2BpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!nvidia-smi"
      ],
      "metadata": {
        "id": "Evtuqfa82E-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import assemblyai as aai\n",
        "\n",
        "aai.settings.api_key = \"ASSEMBLY_AI_KEY\""
      ],
      "metadata": {
        "id": "DPE-j-OQ1s_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import HuggingFacePipeline\n",
        "from transformers import AutoTokenizer, pipeline\n",
        "import torch\n",
        "from langchain import PromptTemplate, LLMChain\n"
      ],
      "metadata": {
        "id": "jCzhWgRq2Nb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"tiiuae/falcon-7b-instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "\n",
        "pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    trust_remote_code=True,\n",
        "    device_map=\"auto\",\n",
        "    max_length=200,\n",
        "    do_sample=True,\n",
        "    top_k=10,\n",
        "    num_return_sequences=1,\n",
        "    eos_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline = pipeline, model_kwargs = {'temperature':0})"
      ],
      "metadata": {
        "id": "TyJHCGD4A3MO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install gradio -q"
      ],
      "metadata": {
        "id": "Ivss9A4bykkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import time"
      ],
      "metadata": {
        "id": "Iw4ouQkXyn2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe(audio):\n",
        "\n",
        "  transcriber = aai.Transcriber()\n",
        "  transcript = transcriber.transcribe(audio)\n",
        "\n",
        "  print(transcript.text)\n",
        "\n",
        "  return transcript.text\n",
        "\n",
        "  #template = \"\"\"\n",
        "  #You are an intelligent chatbot. Help the following question with brilliant answers.\n",
        "  #Question: {instruction}\n",
        "  #Answer:\"\"\"\n",
        "\n",
        "  #prompt = PromptTemplate(template=template, input_variables=[\"instruction\"])\n",
        "\n",
        "  #llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "  #instruction = transcript.text\n",
        "\n",
        "  #return(llm_chain.run(instruction))\n"
      ],
      "metadata": {
        "id": "HfIf21GvyyoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(\n",
        "    title = 'Real-time AI-based Audio Transcription, Recognition and Translation Web App',\n",
        "    fn=transcribe,\n",
        "    inputs=[\n",
        "        gr.inputs.Audio(source=\"microphone\", type=\"filepath\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        \"textbox\"\n",
        "    ],\n",
        "    live=True).launch()"
      ],
      "metadata": {
        "id": "oOH370IizR8O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}